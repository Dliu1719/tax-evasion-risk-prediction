{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tax Evasion Prediction — A Machine Learning Case Study\n",
    "\n",
    "**Author:** Dong Liu  \n",
    "**Last updated:** Feb 27, 2026\n",
    "\n",
    "### Executive Overview\n",
    "This notebook walks through end‑to‑end development of a tax evasion prediction model, including data loading, cleaning, exploratory analysis, feature engineering, model training, and evaluation.  \n",
    "The focus is clarity and reproducibility. The **original modeling logic and outputs are preserved**; only structure and documentation were added for portfolio presentation.\n",
    "\n",
    "### How to Run\n",
    "- Environment: Python 3.x, common data‑science stack (pandas, numpy, scikit‑learn, matplotlib, seaborn, etc.).  \n",
    "- Reproducibility: set a global random seed where applicable.  \n",
    "- Run all cells from top to bottom. If data files are required, place them under a `data/` folder at project root or adjust paths accordingly.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "1. Data Loading & Cleaning\n",
    "2. Model Training  \n",
    "3. Evaluation & Error Analysis  \n",
    "4. Insights & Next Steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Tax Evation Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading & Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In Logistic Regression, missing necessary interaction terms will cause bias. KNN is completely non-parametric, and it can naturally capture complex interaction terms without requiring explicit interaction terms in the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, roc_curve, roc_auc_score, RocCurveDisplay\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "audit = pd.read_csv('Data-Audit.csv')\n",
    "audit.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lookup the missing values\n",
    "print(audit.isna().sum())\n",
    "\n",
    "# Display rows where Money_Value is missing\n",
    "print(audit[audit[\"Money_Value\"].isna()])\n",
    "\n",
    "# Remove the rows with missing money value\n",
    "audit.dropna(axis=0, subset= 'Money_Value', inplace=True)\n",
    "print(f'remaining number of rows: {len(audit)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = audit.drop(columns = ['Risk'])\n",
    "y = audit['Risk']\n",
    "display(X.head())\n",
    "display(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data spliting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state = 13, stratify=y)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and train the logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels on the test set\n",
    "y_pred_log = model.predict_proba(X_test)[:, 1] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model (Threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous to binary predictions\n",
    "y_pred_log_bin_1 = np.where(y_pred_log > 0.5, 1, 0)\n",
    "y_pred_log_bin_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_log_1 = confusion_matrix(y_test, y_pred_log_bin_1)\n",
    "print(cm_log_1)\n",
    "\n",
    "# Compute Accuracy\n",
    "accuracy_log_1 = accuracy_score(y_test, y_pred_log_bin_1)\n",
    "error_rate_log_1 = 1 - accuracy_log_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(cm_log_1, annot=True, \n",
    "            fmt='d', cmap='Blues')\n",
    "\n",
    "ax.set_title('Logistic Regression: Confusion Matrix with Threshold 0.5 \\n')\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values')\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model (Threshold = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Continuous to binary predictions\n",
    "y_pred_log_bin_2 = np.where(y_pred_log > 0.6, 1, 0)\n",
    "y_pred_log_bin_2[:10]\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_log_2 = confusion_matrix(y_test, y_pred_log_bin_2)\n",
    "print(cm_log_2)\n",
    "\n",
    "# Compute Accuracy\n",
    "accuracy_log_2 = accuracy_score(y_test, y_pred_log_bin_2)\n",
    "error_rate_log_2 = 1 - accuracy_log_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix\n",
    "ax = sns.heatmap(cm_log_2, annot=True, \n",
    "            fmt='d', cmap='Blues')\n",
    "\n",
    "ax.set_title('Logistic Regression: Confusion Matrix with Threshold 0.6\\n')\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values')\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print(f\"\\nAccuracy with threshold 0.5: {accuracy_log_1 * 100:.2f}%\")\n",
    "print(f\"Error Rate with threshold 0.5: {error_rate_log_1 * 100:.2f}%\")\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nAccuracy with threshold 0.6: {accuracy_log_2 * 100:.2f}%\")\n",
    "print(f\"Error Rate with threshold 0.6: {error_rate_log_2 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the model with threshold 0.6 has higher accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Model AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC\n",
    "fpr_audit, tpr_audit, thresholds_audit = roc_curve(y_test, y_pred_log)\n",
    "auc_audit = roc_auc_score(y_test, y_pred_log)\n",
    "roc_curve_audit = RocCurveDisplay(fpr=fpr_audit, tpr=tpr_audit, \n",
    "                                roc_auc=auc_audit,\n",
    "                                estimator_name='Logistic Regression')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "roc_curve_audit.plot(ax=ax)\n",
    "ax.set_ylabel(\"True Positive Rate (TPR)\", fontsize=20)\n",
    "ax.set_xlabel(\"False Positive Rate (FPR)\", fontsize=20)\n",
    "ax.set_title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"The AUC score is {auc_audit*100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC visualize the tradeoff between the TPR and FPR at all possible decision thresholds, not only the 0.6 and 0.5 threshold we have compared.  \n",
    "The ROC plot shows that the model contains high TPR rate while keeping the FPR rate low, indicating that the model perform well across differnt shresholds.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this context, the government prioritizes identifying firms with a high probability of tax evasion. False negatives (FN) are more concerning than false positives (FP) because:  \n",
    "\n",
    "1. A false negative (FN) occurs when the model fails to detect a tax evader, undermining efforts to increase tax revenue.\n",
    "\n",
    "2. A false positive (FP) leads to unnecessary audits, but the financial and administrative costs are relatively lower compared to the consequences of missing actual evaders.\n",
    "\n",
    "Based on the ROC curve, the model effectively keeps the overall false positive rate low. \n",
    "\n",
    "Increasing the threadshold will increase the FN rate, while decreading the shredshold will increase the FP rate. Given the government’s focus on minimizing false negatives, I would recommend a lower shredshold in this case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model Unscaled (k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run KNN5\n",
    "knn_5 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_5.fit(X_train, y_train)\n",
    "knn_5_prob = knn_5.predict_proba(X_test)[:, 1] \n",
    "\n",
    "# Apply 0.5 threshold\n",
    "knn_5_pred = (knn_5_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy_knn_5 = accuracy_score(y_test, knn_5_pred)\n",
    "error_rate_knn_5 = 1 - accuracy_knn_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "knn_5_cm = confusion_matrix(y_test, knn_5_pred)\n",
    "print(knn_5_cm)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "ax = sns.heatmap(knn_5_cm, annot=True, \n",
    "            fmt='d', cmap='Blues')\n",
    "\n",
    "ax.set_title('KNN_5 Confusion Matrix \\n')\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values')\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print accuracy results\n",
    "\n",
    "print(f\"KNN 5 Error Rate: {error_rate_knn_5 * 100:.2f}%\")\n",
    "print(f\"KNN 5 Overall acuracy: {accuracy_knn_5 * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under 5-neighbour KNN, the proportion of the firms predicted to evade their taxes actually evaded taxes: $\\frac{138}{138+4}= 95.8\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model Scaled (k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()  # Initialize the scalar\n",
    "X_train_scaled = scaler.fit_transform(X_train)  \n",
    "X_test_scaled = scaler.transform(X_test)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run KNN5 with scaled X\n",
    "knn_5_scaled = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_5_scaled.fit(X_train_scaled, y_train)\n",
    "knn_5_prob_scaled = knn_5_scaled.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Apply 0.5 threshold\n",
    "knn_5_pred_scaled = (knn_5_prob_scaled > 0.5).astype(int)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy_knn_5_scaled = accuracy_score(y_test, knn_5_pred_scaled)\n",
    "error_rate_knn_5_scaled = 1 - accuracy_knn_5_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "knn_5_scaled_cm = confusion_matrix(y_test, knn_5_pred_scaled)\n",
    "print(knn_5_scaled_cm)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "ax = sns.heatmap(knn_5_scaled_cm, annot=True, \n",
    "            fmt='d', cmap='Blues')\n",
    "\n",
    "ax.set_title('KNN_5_scaled Confusion Matrix \\n')\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values')\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"KNN 5 scaled Error Rate: {error_rate_knn_5_scaled * 100:.2f}%\")\n",
    "print(f\"KNN 5 scaled Overall acuracy: {accuracy_knn_5_scaled * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using scaled data, the proportion of the firms predicted to evade their taxes actually evaded taxes: $\\frac{144}{144+5}= 96.64\\%$\n",
    "\n",
    "The model with scaling performs better in this case. It has higer overall accuracy, lower FNR and FPR. The reason that unscaled data makes better prediction could due to the predictors $x_i \\in X$ with lower variation weight more in the true prediction function than those with higher variation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total Sample Size: {len(y)}\")\n",
    "n = int(np.sqrt(len(y)))\n",
    "print(n)\n",
    "ks = list(range(1, 27, 2))  \n",
    "para = {'n_neighbors': ks}\n",
    "print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the KNN classifier\n",
    "knni = KNeighborsClassifier()\n",
    "\n",
    "# Set up 5-fold cross-validation scheme\n",
    "kfcv = KFold(5, random_state=13, shuffle=True)\n",
    "knn_cv = GridSearchCV(knni, para, cv=kfcv) \n",
    "\n",
    "# Fit the model\n",
    "knn_cv.fit(X_train, y_train)\n",
    "knn_cv_pred = knn_cv.predict(X_test)\n",
    "knn_cv_pred_acc = accuracy_score(y_test, knn_cv_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Best parameters :\", knn_cv.best_params_)\n",
    "print(f'Best cross validation score: {knn_cv.best_score_:.4f}')\n",
    "print(f'Accuracy score:{ knn_cv_pred_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on 5-fold cross validation, the model yields the best performance when $k=1$, with cross-valication score 96.39% and accuracy score 95.88 %.\n",
    "It could due to the sample size is small, only 775, larger k could lead to underfitting. \n",
    "\n",
    "In the long run, if the government relies too heavily on a KNN model with k=1, several issues may arise:  \n",
    "\n",
    "Overfitting: The model is too flexible and may not generalize well.  \n",
    "\n",
    "Limited Sample Size: With only 775 samples, the data may not represent the entire population.  \n",
    "\n",
    "Bias in Detection: The model may miss tax evaders with different characteristics not captured in the training data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Insights & Next Steps\n",
    "\n",
    "**Key Takeaways (from current results):**\n",
    "- Summarize the strongest signals/features.\n",
    "- Note model performance (accuracy/AUC/F1/etc.) as reported above.\n",
    "- Mention any class imbalance handling, validation scheme, and error analysis observations.\n",
    "\n",
    "**Potential Improvements (future work):**\n",
    "- Try calibrated probabilities and threshold tuning for business KPIs.\n",
    "- Evaluate additional models (e.g., gradient boosting, stacking) with proper cross‑validation.\n",
    "- Add domain features (e.g., behavior over time, peer comparisons, network features).\n",
    "- Build a lightweight pipeline (sklearn `Pipeline`) for portability.\n",
    "- Draft a short model card (intended use, limitations, fairness).\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (clean_env)",
   "language": "python",
   "name": "clean_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
